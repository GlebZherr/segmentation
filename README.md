# segmentation
Web text extraction tool

## Основной pipeline

1. Инструмент разметки: http://<ваш_сервер>:8000/ \
   Для получения размеченной выборки. \
   Flask app находится в директории segmentation/blocks_webapp, приложение запускается скриптом index_blocks.py

2. На основе размеченных данных создается датасет для обучения модели.\
   Сама база банных адресов, блоков, контента страниц и разметки находится в файле data/blocks.sqlite\
   Датасет собирается скриптом make_dataset.py, который находится в дир: features_extract\
   Созданный json-файл будет находится в дир data, имя файла features.json.gzip

3. Валидация модели и подбор гиперпараметров\
   Jupyter notebook: Segclf_domains.ipynb в дир notebooks

4. Обучение модели\
   Jupyter notebook: Segclf.ipynb\
   В результате создается файл модели model_weights_sqrt.cbm

5. Предсказание меток блоков по url-адресу страницы\
   Файл predictor.py в дир: lib\
   В нем находится функция wrapper, которая запрашивает страницу, парсит ее на блоки текста, каждому блоку присваивает метку\
   Пример запуска в секции "if name == '__main__'"\
   Для скорости модель должна быть загружена в память предварительно и оставаться там персистентно\
   Пример предзагрузки модели в скрипте приложения разметки

6. Последний этап, собственно формирование текста новости на основе предсказанной разметки\
   Пример находится в файле load_examples.py в дир features_extract\
   Формирование текста функция get_news_content, пример использования в секции "if name == '__main__'"\
   Эту функцию надо еще доделывать в зависимости от потребности заказчика, но можно использовать и таком виде

